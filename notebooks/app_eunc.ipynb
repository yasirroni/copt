{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Expected Unserved Energy Cost Calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Usage**\n",
    "\n",
    "1. In Google Colab, press `ctrl+F9`\n",
    "1. Press `run anyway` if a warning message appear.\n",
    "1. Wait for the UI to show up (until a loading circle in the bottom of notebook stopped).\n",
    "1. Upload files by pressing upload button.\n",
    "1. Press compute to run simulation.\n",
    "1. Press `ctrl+F7` to restart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Input Format**\n",
    "\n",
    "### Forced outage rate input format\n",
    "\n",
    "|No |Unit Name  |Capacity (MW)  |FOR (Outage)   |Status |\n",
    "|---|-----------|---------------|---------------|-------|\n",
    "|1  |COAL-1     |50             |0.1            |1      |\n",
    "|2  |COAL-2     |20             |0.1            |0      |\n",
    "|3  |COAL-3     |50             |0.2            |1      |\n",
    "|4  |COAL-4     |30             |0.1            |1      |\n",
    "\n",
    "Note:\n",
    "\n",
    "1. status denotes that the generating unit is considered (1) or not (0) in making COPT table.\n",
    "\n",
    "### Profile input format\n",
    "\n",
    "|No     |Demand (MW)    |\n",
    "|-------|---------------|\n",
    "|1      |150            |\n",
    "|...    |...            |\n",
    "|...    |...            |\n",
    "|8760   |125            |\n",
    "\n",
    "### VOLL input format\n",
    "\n",
    "VOLL can use `_` and `,` separator for thousands and `.` for cents, eg: `15_000_000.00`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "!pip install -qqq itables  # noqa E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "import itertools\n",
    "\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "from itables import show  # noqa E402\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "COPT_COLUMNS = ['Combined Capacity',\n",
    "                'Individual Probability',\n",
    "                'Cumulative Probability',\n",
    "                # 'Reversed Cumulative Probability',\n",
    "                ]\n",
    "CC_COLUMNS = ['Scenario Name',\n",
    "              'Penetration Level (%)',\n",
    "              'VRE Installed Capacity (MWp)',\n",
    "              'EENS After VRE Installation (MWh)',\n",
    "              'Delta Load to Equalize VRE (MW)',\n",
    "              'Capacity Credit (%)',\n",
    "              ]\n",
    "NUMPY_ZERO = np.float64(0)\n",
    "\n",
    "IDX_CAP = 0\n",
    "IDX_INP = 1\n",
    "IDX_CMP = 2\n",
    "# IDX_RCP = 4\n",
    "\n",
    "# setting numpy print option decimal places\n",
    "decimal_places = 4\n",
    "np.set_printoptions(precision=decimal_places, suppress=True)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "\n",
    "# copt\n",
    "# @jit(nopython=True)\n",
    "def get_copt(\n",
    "        capacities,\n",
    "        outage_rates,\n",
    "        status,\n",
    "        row_threshold=None,\n",
    "        min_cum_prob=0.0001,\n",
    "        row_reduced_to=50):\n",
    "    # filter only available generator\n",
    "    # TODO: sort based on frequency of capacities, not capacities size\n",
    "    generator_list = [[cap, 1 - out]\n",
    "                      for cap, out, stat\n",
    "                      in sorted(zip(capacities, outage_rates, status), reverse=True)\n",
    "                      if stat]\n",
    "\n",
    "    # make tables for each generator\n",
    "    # TODO: Tables already support derating, input data should also support it\n",
    "    # from excel\n",
    "    tables = [np.array([generator, [0, 1 - generator[1]]])\n",
    "              for generator in generator_list]\n",
    "\n",
    "    table = tables[0].copy()  # copy to avoid modifying data\n",
    "    for table_ in tables[1:]:\n",
    "        # combine tables\n",
    "        table = _combine_tables(table, table_)\n",
    "\n",
    "        # combine duplicate\n",
    "        table = np.array([[k, sum([x[1] for x in list(g)])]\n",
    "                          for k, g in itertools.groupby(table, lambda x:x[0])])\n",
    "\n",
    "        # # merge insignificant\n",
    "        # try:\n",
    "        #     if len(table) > row_threshold:\n",
    "        #         table = _merge_insignificant(table, min_cum_prob)\n",
    "        # except Exception:  # TypeError\n",
    "        #     pass\n",
    "\n",
    "        # # merge resample\n",
    "        # try:\n",
    "        #     if len(table) > row_threshold:\n",
    "        #         table = _merge_resample(table, row_reduced_to)\n",
    "        # except Exception:  # TypeError\n",
    "        #     pass\n",
    "\n",
    "    table = np.hstack((table,\n",
    "                       # Cumulative Probability\n",
    "                       np.atleast_2d(np.cumsum(table[::-1, IDX_INP])[::-1]).T,\n",
    "                       # # Reversed Cumulative Probability\n",
    "                       # np.atleast_2d(np.cumsum(table[:, IDX_INP])).T,\n",
    "                       ))\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def _combine_tables(table, table_):\n",
    "    # TODO:\n",
    "    # Compare between:\n",
    "    #   1. flatten + transpose\n",
    "    #   2. np.array([table[:, 0]]).T\n",
    "    table = np.hstack((\n",
    "        (\n",
    "            np.expand_dims(table[:, IDX_CAP], axis=1) + table_[:, IDX_CAP]\n",
    "        ).reshape(-1, 1),  # sum capacity\n",
    "        (\n",
    "            np.expand_dims(table[:, IDX_INP], axis=1) * table_[:, IDX_INP]\n",
    "        ).reshape(-1, 1),  # multiply probability\n",
    "    ))\n",
    "\n",
    "    # sort table\n",
    "    table = table[(-table[:, IDX_CAP]).argsort(), :]\n",
    "    return table\n",
    "\n",
    "\n",
    "# @jit(nopython=True)\n",
    "def _merge_insignificant(table, min_cum_prob):\n",
    "    # merge insignificant\n",
    "    cum_prob = np.cumsum(table[::-1, IDX_INP])[::-1]\n",
    "    mask_insignificant = cum_prob < min_cum_prob\n",
    "    if mask_insignificant.sum() > 1:\n",
    "        # NOTE:\n",
    "        # ROUNDUP: More accurate but reduce EENS\n",
    "        # ROUNDDOWN: Not accurate and will amplify EENS\n",
    "        # ROUNDUPDOWN: Not accurate, increase EENS, but better than ROUNDDOWN\n",
    "\n",
    "        # # round up approach\n",
    "        # table = table[~mask_insignificant, :]  # cut\n",
    "        # table[-1, IDX_INP] = 1 - table[:-1, IDX_INP].sum()  # replace\n",
    "\n",
    "        # # round down approach\n",
    "        # table = np.vstack((\n",
    "        #     table[~mask_insignificant, :],  # cut\n",
    "        #     np.array([[NUMPY_ZERO, table[mask_insignificant, 1].sum()]])\n",
    "        # ))\n",
    "\n",
    "        # # round up down approach\n",
    "        # removed_cap = table[mask_insignificant, IDX_CAP]\n",
    "        # removed_inp = table[mask_insignificant, IDX_INP]\n",
    "        # weight_to_top = (removed_cap\n",
    "        #                  / table[~mask_insignificant, IDX_CAP][-1])\n",
    "        # zero_inp = (\n",
    "        #     table[-1, IDX_INP]  # zero_inp\n",
    "        #     + np.sum(removed_inp * (1 - weight_to_top))\n",
    "        # )\n",
    "        # table = table[~mask_insignificant, :]  # cut\n",
    "        # table[-1, IDX_INP] = (\n",
    "        #     table[-1, IDX_INP]  # top_inp\n",
    "        #     + np.sum(removed_inp * weight_to_top)\n",
    "        # )\n",
    "        # table = np.vstack((\n",
    "        #     table,\n",
    "        #     np.array([[NUMPY_ZERO, zero_inp]])\n",
    "        # ))\n",
    "\n",
    "        pass\n",
    "\n",
    "    # TODO:\n",
    "    # Implement resample,\n",
    "    # useful for big COPT table, triggered only if max table length achieve\n",
    "    return table\n",
    "\n",
    "\n",
    "def _merge_resample(table, row_reduced_to):\n",
    "    group_size = len(table) // row_reduced_to\n",
    "    reduced_row = group_size * row_reduced_to\n",
    "\n",
    "    # cut start from index 0 (most likely to be not used by EENS?)\n",
    "    removed_cap = table[:reduced_row, IDX_CAP].reshape(row_reduced_to, -1)[:, 1:]\n",
    "    removed_inp = table[:reduced_row, IDX_INP].reshape(row_reduced_to, -1)[:, 1:]\n",
    "    resampled_cap = np.atleast_2d(\n",
    "        table[:reduced_row + group_size:group_size, IDX_CAP]).T\n",
    "    resampled_inp = np.atleast_2d(\n",
    "        table[:reduced_row + group_size:group_size, IDX_INP]).T\n",
    "\n",
    "    distance_top = ((resampled_cap[:-1] - removed_cap)\n",
    "                    / np.diff(resampled_cap, axis=0))\n",
    "    distance_bot = 1 - distance_top\n",
    "\n",
    "    resampled_inp[:-1] = (resampled_inp[:-1]  # top, distance_bot\n",
    "                          + np.atleast_2d(np.sum(removed_inp\n",
    "                                                 * distance_bot, axis=1)).T)\n",
    "    resampled_inp[1:] = (resampled_inp[1:]  # bot, distance_top\n",
    "                         + np.atleast_2d(np.sum(removed_inp\n",
    "                                                * distance_top, axis=1)).T)\n",
    "\n",
    "    resampled_tab = np.hstack((resampled_cap, resampled_inp))\n",
    "    table = np.vstack((resampled_tab, table[reduced_row + 1:]))\n",
    "    return table\n",
    "\n",
    "\n",
    "# lolp\n",
    "@jit(nopython=True)\n",
    "def get_lolp(capacity, cumulative_probability, demand):\n",
    "    \"\"\"\n",
    "    format:\n",
    "        capacity (descend)\n",
    "        cumulative_probability(descend)\n",
    "    \"\"\"\n",
    "    # NOTE: Lowest COPT table < lowest demand cause error\n",
    "    try:\n",
    "        idx = np.where(capacity < demand)[0][0]\n",
    "    except Exception:  # IndexError\n",
    "        idx = -1\n",
    "    return cumulative_probability[idx]\n",
    "\n",
    "\n",
    "# eens\n",
    "@jit(nopython=True)\n",
    "def get_eens(capacity, individual_probability, demand):\n",
    "    \"\"\"\n",
    "    format:\n",
    "        capacity\n",
    "        individual_probability\n",
    "    \"\"\"\n",
    "    return sum(individual_probability\n",
    "               * (capacity < demand)\n",
    "               * (demand - capacity))\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def find_delta_load(lb, ub, table, net_loads, eens, tol=0.0001):\n",
    "    # lb_0 = 0\n",
    "    # ub_0 = max(sun)\n",
    "    # delta_load_0 = max(sun) / 2\n",
    "    eens_delta_load = np.inf\n",
    "    while abs(eens_delta_load - eens) > tol:\n",
    "        delta_load = (lb + ub) * 0.5\n",
    "        eens_delta_load = sum([get_eens(table[:, IDX_CAP], table[:, IDX_INP], net_load)\n",
    "                               for net_load in net_loads + delta_load])\n",
    "        if eens_delta_load > eens:\n",
    "            ub = delta_load\n",
    "        else:\n",
    "            lb = delta_load\n",
    "    return delta_load, eens_delta_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# Uploader class for input\n",
    "class Uploader:\n",
    "    def __init__(self, name=None):\n",
    "        if name is None:\n",
    "            self._name = ' '\n",
    "        else:\n",
    "            self._name = f' {name} '\n",
    "\n",
    "        # uploader\n",
    "        self._file_upload = widgets.FileUpload(\n",
    "            accept='.csv*',  # Accepted file extension\n",
    "            multiple=False  # True to accept multiple files upload else False\n",
    "        )\n",
    "\n",
    "        self.box = widgets.VBox(\n",
    "            children=(\n",
    "                self._file_upload,\n",
    "                widgets.Label(value=f'Upload{self._name}in .csv Format')\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def get_dataframe(self):\n",
    "        return get_dataframe_from_widget(self._file_upload)\n",
    "\n",
    "\n",
    "# widgets\n",
    "def write_file_from_bytes_data(bytes_data, file_name='NAME.csv'):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        f.write(bytes_data)\n",
    "\n",
    "\n",
    "def _get_content_and_name_ipywidget_8(file_upload):\n",
    "    return (\n",
    "        file_upload.value[0]['content'],\n",
    "        file_upload.value[0]['name'],\n",
    "    )\n",
    "\n",
    "\n",
    "def _get_content_and_name_ipywidget_7(file_upload):\n",
    "    for _key, value in file_upload.value.items():\n",
    "        return (\n",
    "            value['content'],\n",
    "            value['metadata']['name']\n",
    "        )\n",
    "\n",
    "\n",
    "# get ipywidgets version\n",
    "IPYWIDGETS_VERSION = ipywidgets.__version__.split('.')[0]\n",
    "if IPYWIDGETS_VERSION == '8':\n",
    "    get_content_and_name = _get_content_and_name_ipywidget_8\n",
    "elif IPYWIDGETS_VERSION == '7':\n",
    "    get_content_and_name = _get_content_and_name_ipywidget_7\n",
    "else:\n",
    "    print('Please install either ipywidgets 7 or 8, for example:')\n",
    "    print('pip install ipywidgets==7.7.2')\n",
    "\n",
    "\n",
    "def get_dataframe_from_widget(file_upload):\n",
    "    # get content and file name\n",
    "    content, name = get_content_and_name(file_upload)\n",
    "\n",
    "    # from bytes data to csv file\n",
    "    write_file_from_bytes_data(content, file_name=name)\n",
    "\n",
    "    # pandas read csv\n",
    "    return pd.read_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# initiate widgets\n",
    "output = widgets.Output()\n",
    "for_data_uploader = Uploader(name='FOR Data')\n",
    "demand_profile_data_uploader = Uploader(name='Demand Profile Data')\n",
    "voll_widget = widgets.Text(\n",
    "    value='15_000_000.00',\n",
    "    description='VOLL: ',\n",
    "    disabled=False\n",
    ")\n",
    "currency_widget = widgets.Dropdown(\n",
    "    options=['IDR', 'USD'],\n",
    "    value='IDR',\n",
    "    description='Currency: ',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "# button action\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        # TODO: option to set COPT threshold and option to show/hide COPT\n",
    "        # print\n",
    "        print(\"Computing...\")\n",
    "\n",
    "        # filter for inputs\n",
    "        df = for_data_uploader.get_dataframe()\n",
    "        capacities = df['Capacity (MW)'].tolist()\n",
    "        outage_rates = df['FOR (Outage)'].tolist()\n",
    "        status = df['Status'].tolist()\n",
    "\n",
    "        # # to print input table, use:\n",
    "        # pd.DataFrame(data={'capacities': capacities,\n",
    "        #                    'outage_rates': outage_rates,\n",
    "        #                    'status': status},\n",
    "        #              index=pd.RangeIndex(1, len(capacities) + 1, 1)).head(10)\n",
    "\n",
    "        table = get_copt(capacities, outage_rates, status, row_threshold=None)\n",
    "        df = pd.DataFrame(data=table,\n",
    "                          columns=COPT_COLUMNS,\n",
    "                          index=pd.RangeIndex(1, len(table) + 1, 1, name='No'),\n",
    "                          )\n",
    "        # # show copt table\n",
    "        # show(df, \"COPT Table\")\n",
    "\n",
    "        # to save COPT in csv\n",
    "        # CASE_NAME = 'COPT Case.csv'\n",
    "        # df.to_csv(f'../results/COPT_{CASE_NAME}')\n",
    "\n",
    "        # TODO: copt downloader\n",
    "\n",
    "        # filter demand inputs\n",
    "        demands = demand_profile_data_uploader.get_dataframe()['Demand (MW)'].values\n",
    "        max_demand = np.max(demands)\n",
    "        n_hour = len(demands)\n",
    "\n",
    "        # LOLP\n",
    "        lolp = get_lolp(table[:, IDX_CAP], table[:, IDX_CMP],\n",
    "                        max_demand)\n",
    "        print(f'LOLP (using anual peak load): {lolp * 100:.6f} %')\n",
    "        print(f'LOLE (using anual peak load): {lolp * 365:.6f} day/year')\n",
    "\n",
    "        # LOLE\n",
    "        # NOTE:\n",
    "        #   Be careful if using sliced or reduced COPT\n",
    "        #   Lowest COPT table < lowest demand cause error\n",
    "        lole = sum([get_lolp(table[:, IDX_CAP], table[:, IDX_CMP], demand)\n",
    "                    for demand in demands])\n",
    "        print(f'LOLE (using {n_hour} hour demand profile): {lole:.6f} hour/year')\n",
    "\n",
    "        # EENS\n",
    "        eens = sum([get_eens(table[:, IDX_CAP], table[:, IDX_INP], demand)\n",
    "                    for demand in demands])\n",
    "        print(f'Total EENS (using {n_hour} hour demand profile): {eens:.2f} MWh')\n",
    "\n",
    "        # EUNC\n",
    "        VOLL = float(voll_widget.value.replace(',', ''))\n",
    "        print(f'Total EUNC from EENS: {currency_widget.value} {VOLL * eens:,.2f}')\n",
    "\n",
    "\n",
    "# initiate button\n",
    "button = widgets.Button(description=\"Compute!\")\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# interface\n",
    "widgets.VBox((for_data_uploader.box,\n",
    "              demand_profile_data_uploader.box,\n",
    "              voll_widget,\n",
    "              currency_widget,\n",
    "              button,\n",
    "              output,\n",
    "              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
